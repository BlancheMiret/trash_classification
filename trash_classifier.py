# -*- coding: utf-8 -*-
"""trash_classifier_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q9TP56xTOb0JYDDZGLolhLH-ZTts1YMT

## I. Getting data

### Prep for kaggle data
"""

!pip install -q kaggle

# Import kaggle.json conainting username and key from kaggle
from google.colab import files
files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

"""### Download kaggle data"""

!kaggle datasets list -s garbage

!kaggle datasets download -d mostafaabla/garbage-classification

!mkdir garbage_data

!unzip garbage-classification.zip -d garbage_data/

"""### Load data"""

from fastai.vision.all import *
# from fastcore.all import *
from fastai.vision.widgets import * # Includes the ImageClassifierCleaner for instance

dls = DataBlock(
    blocks = (ImageBlock, CategoryBlock), # input are images, outputs are categories
    get_items = get_image_files, # returns list of images in a path
    splitter = RandomSplitter(valid_pct=0.2, seed=42), # splits data between training and validation (20%) sets
    get_y=parent_label, # label of images is the name of their parent
    item_tfms=[Resize(192, method='squish')] # resize images, 'squish' instead of 'crop'
).dataloaders("garbage_data/garbage_classification", bs=32)

# À tester auss :
#     item_tfms=RandomResizedCrop(224, min_scale=0.5),
#     batch_tfms=aug_transforms(), #transformation par batch

dls.show_batch(max_n=6)

"""## II. Model

### Training
"""

learn = vision_learner(dls, resnet18, metrics=error_rate)
learn.fine_tune(3)

learn.dls.vocab # Plastic is 8

"""Below: this is the confusion matrix on the VALIDATION SET, which has not been seen in training (But used as metric during training?)."""

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()

"""- Metal is confused with battery (logic) and also brown-glass or white-glass.
- shoes are often confused with clothes, with is normal because there are many shoes in the cloth dataset! (see below). Clothes are also confused with shoes. Also confused with brown-glass.
- White glass is confused with plastic, metal, and biological??
- However brown-glass is well recognised, not confused with metal or shoes.
- Card board and paper can be mixed
"""

interp.plot_top_losses(10, nrows=1)
# Shows images with highest loss when predicting
# Prediction / actual / loss / probability
# probability is the confidence level assigned to the prediction

# fast AI GUI for data cleaning (in case of misclassification in the labels of the dataset)
# View the highest loss images
cleaner = ImageClassifierCleaner(learn)
cleaner

"""- We see that many shoes are misclassified in "clothes" instead of "shoes"
- In the "trash" category, many toothbrushes, could go in the plastic category...? Masks and diapers otherwise. Not very diverse.
- The images of toothbrushes, diapers, even masks, are not from real life situation. Product photos, not the best help for the model...?
"""

# Supprimer les images

# for idx in cleaner.delete():
#   cleaner.fns[idx].unlink()

# Déplacer les images re-labellisées par le ImageClassifierCleaner

path = Path("garbage_data/garbage_classification")

for idx, cat in cleaner.change():
  shutil.move(str(cleaner.fns[idx]), path/cat)

"""New training with cleaned data"""

path

# dls = dls.new(
#     item_tfms=[Resize(192, method='squish')]
#     #batch_tfms=aug_transforms(),
# )
# dls = dls.dataloaders(path)

# Up: list index out of range in dls.dataloaders(path). let's try recreate one from scratch

dls = DataBlock(
    blocks = (ImageBlock, CategoryBlock), # input are images, outputs are categories
    get_items = get_image_files, # returns list of images in a path
    splitter = RandomSplitter(valid_pct=0.2, seed=42), # splits data between training and validation (20%) sets
    get_y=parent_label, # label of images is the name of their parent
    item_tfms=[Resize(192, method='squish')] # resize images, 'squish' instead of 'crop'
).dataloaders(path, bs=32)

learn = vision_learner(dls, resnet18, metrics=error_rate)
learn.fine_tune(3)

"""Les chiffres ont à peine bougé. Vérifions que le dataset a bien été modifié."""

cleaner = ImageClassifierCleaner(learn)
cleaner

# Du coup je ne suis pas sûre...

"""**For a better trash_classifier**
- add weight of the objects as input in the model
- could ALSO add shape detector, to estimate size / volume of the object
--> with weight + volume first estimate of material

### Testing the model

#### Check on validation set

(Already done with confusion matrix, but let's see)
"""

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

i= 0
for root, dir, files in os.walk(path/'plastic'):
  for img in files:
    img_path = Path(f"{root}/{img}")
    plt.imshow(mpimg.imread(img_path))
    plt.axis('off')
    plt.show()
    is_plastic, _, probs = learn.predict(PILImage.create(img_path))
    print(f"This is: {is_plastic}")
    print(f"Probability it's plastic: {probs[8]:.4f}") # I put 8th because it's the 9th directory displayed in my files, but, how to be sure? --> learn.dls.vocab
    print(probs)
    print("====================")
    i+= 1
    if i > 9 : break

"""#### On real world images"""

from google.colab import files

test_data_path = Path("garbage_data/test_data")
!mkdir garbage_data/test_data
!mkdir garbage_data/test_data/plastic
files.upload(test_data_path/'plastic')

!mkdir -p garbage_data/test_data/cardboard
files.upload(test_data_path/'cardboard')

!mkdir -p garbage_data/test_data/shoes
files.upload(test_data_path/'shoes')

!mkdir -p garbage_data/test_data/clothes
files.upload(test_data_path/'clothes')

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

"""##### plastic

100% of errors, plastic is not even being close in the probas.

(Des tests pour donner une image bonne taille au modèle, voir si ça aide... Mais probablement qu'à l'inférence, le modèle le fait automatiquement. La question est : comment.

Squish, comme à l'entraînement ?)
"""

test_img_path = Path("garbage_data/test_data/plastic/IMG_5339.jpg")
test_img = PILImage.create(test_img_path)
#im.resize((64,64))
test_img

test_img.resize(192,192)

test_img = test_img.resize((192,192))

test_img

import os
from matplotlib.pyplot import figure

for root, dir, files in os.walk(test_data_path/'plastic'):
  for img in files:
    img_path = Path(f"{root}/{img}")
    plt.imshow(mpimg.imread(img_path))
    plt.axis('off')
    #figure(figsize=(5, 5))#, dpi=80) # Trying to display it smaller, no idea
    plt.show()
    category, _, probs = learn.predict(PILImage.create(img_path).resize((192,192))) ###
    print(f"This is: {category}")
    #print(f"Probability it's plastic: {probs[8]:.4f}") # I put 8th because it's the 9th directory displayed in my files, but, how to be sure? --> learn.dls.vocab
    for i, voc in enumerate(learn.dls.vocab):
      print(f"Probability it's {voc}: {probs[i]*100:.2f}%")
    print("==========")

"""- first try: error rate on test data = 100%

##### cardboard

Almost a victory : 45% for cardboard!
"""

for root, dir, files_ in os.walk(test_data_path/'cardboard'):
  for img in files_:
    img_path = Path(f"{root}/{img}")
    plt.imshow(mpimg.imread(img_path))
    plt.axis('off')
    #figure(figsize=(5, 5))#, dpi=80) # Trying to display it smaller, no idea
    plt.show()
    category, _, probs = learn.predict(PILImage.create(img_path).resize((192,192))) ###
    print(f"This is: {category}")
    #print(f"Probability it's plastic: {probs[8]:.4f}") # I put 8th because it's the 9th directory displayed in my files, but, how to be sure? --> learn.dls.vocab
    for i, voc in enumerate(learn.dls.vocab):
      print(f"Probability it's {voc}: {probs[i]*100:.2f}%")
    print("==========")

"""##### shoes

Seems great. How about when there is only one shoe?
"""

for root, dir, files_ in os.walk(test_data_path/'shoes'):
  for img in files_:
    img_path = Path(f"{root}/{img}")
    plt.imshow(mpimg.imread(img_path))
    plt.axis('off')
    #figure(figsize=(5, 5))#, dpi=80) # Trying to display it smaller, no idea
    plt.show()
    category, _, probs = learn.predict(PILImage.create(img_path).resize((192,192))) ###
    print(f"This is: {category}")
    #print(f"Probability it's plastic: {probs[8]:.4f}") # I put 8th because it's the 9th directory displayed in my files, but, how to be sure? --> learn.dls.vocab
    for i, voc in enumerate(learn.dls.vocab):
      print(f"Probability it's {voc}: {probs[i]*100:.2f}%")
    print("==========")

"""##### clothes

Incredible
"""

for root, dir, files_ in os.walk(test_data_path/'clothes'):
  for img in files_:
    img_path = Path(f"{root}/{img}")
    plt.imshow(mpimg.imread(img_path))
    plt.axis('off')
    #figure(figsize=(5, 5))#, dpi=80) # Trying to display it smaller, no idea
    plt.show()
    category, _, probs = learn.predict(PILImage.create(img_path).resize((192,192))) ###
    print(f"This is: {category}")
    #print(f"Probability it's plastic: {probs[8]:.4f}") # I put 8th because it's the 9th directory displayed in my files, but, how to be sure? --> learn.dls.vocab
    for i, voc in enumerate(learn.dls.vocab):
      print(f"Probability it's {voc}: {probs[i]*100:.2f}%")
    print("==========")



